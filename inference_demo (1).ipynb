{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To ensure correct text generation,  \n",
        "we use **only one tokenizer (`tok_fast`)** ‚Äî the same one used during training.\n",
        "\n",
        "This prevents vocabulary mismatch and encoding errors (such as ‚Äú√ê‚Ä¶‚Äù).  \n",
        "The model is loaded from checkpoints and its embeddings are resized  \n",
        "to match the tokenizer‚Äôs vocabulary.\n"
      ],
      "metadata": {
        "id": "0Jn3df8ziiQk"
      },
      "id": "0Jn3df8ziiQk"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "\n",
        "# tokenizer\n",
        "TOK_JSON = '/content/tokenizer_bpe/bpe_16000/tokenizer.json'\n",
        "tok_fast = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=TOK_JSON,\n",
        "    bos_token=\"<bos>\", eos_token=\"<eos>\", unk_token=\"<unk>\", pad_token=\"<pad>\"\n",
        ")\n",
        "\n",
        "# load model\n",
        "mdl = GPT2LMHeadModel.from_pretrained(str(CKPT_DIR)).to(device)\n",
        "mdl.eval()\n",
        "\n",
        "if tok_fast.pad_token is None:\n",
        "    tok_fast.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
        "if tok_fast.eos_token is None:\n",
        "    tok_fast.add_special_tokens({\"eos_token\": \"<eos>\"})\n",
        "\n",
        "mdl.resize_token_embeddings(len(tok_fast))\n",
        "mdl.config.pad_token_id = tok_fast.pad_token_id\n",
        "mdl.config.eos_token_id = tok_fast.eos_token_id\n",
        "\n",
        "#little test\n",
        "probe = \"–ö“Ø“£–µ–ª–ª–µ “ª”ô–º –±”ô—Ö–µ—Ç–ª–µ –∫”©–Ω\"\n",
        "ids = tok_fast(probe)[\"input_ids\"]\n",
        "print(\"RT:\", tok_fast.decode(ids, skip_special_tokens=True))\n",
        "\n",
        "# band number token list\n",
        "vocab = tok_fast.get_vocab()\n",
        "digit_ids = [[tid] for tok, tid in vocab.items() if any(ch.isdigit() for ch in tok)]\n",
        "\n",
        "# generate func\n",
        "def generate(prompt: str, max_new_tokens=80):\n",
        "    enc = tok_fast(prompt, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        out = mdl.generate(\n",
        "            input_ids=enc.input_ids.to(device),\n",
        "            attention_mask=enc.attention_mask.to(device),\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=3,\n",
        "            repetition_penalty=1.2,\n",
        "            length_penalty=0.9,\n",
        "            bad_words_ids=digit_ids or None,\n",
        "            pad_token_id=tok_fast.pad_token_id,\n",
        "            eos_token_id=tok_fast.eos_token_id,\n",
        "        )\n",
        "    text = tok_fast.decode(out[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUNySgVKS0hW",
        "outputId": "45585469-fbb2-48d5-e89a-be1c6a8bf5d8"
      },
      "id": "IUNySgVKS0hW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RT: –ö“Ø“£–µ–ª–ª–µ “ª”ô–º –±”ô—Ö–µ—Ç–ª–µ –∫”©–Ω\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model was tested on several Tatar-language questions.\n",
        "It produced coherent and contextually relevant answers ‚Äî although it did not respond directly to the questions but rather in a news-like manner ‚Äî showing that it learned to \"speak\" Tatar after being trained from scratch."
      ],
      "metadata": {
        "id": "CPXGW2kisVpx"
      },
      "id": "CPXGW2kisVpx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA Demonstration"
      ],
      "metadata": {
        "id": "-5eGTYelx7M3"
      },
      "id": "-5eGTYelx7M3"
    },
    {
      "cell_type": "code",
      "source": [
        "p = [\n",
        "    \"–†”ô“Ø—Ñ —Ö”ô–∑—Ä”ô—Ç –ì–∞–π–Ω–µ—Ç–¥–∏–Ω –Ω”ô—Ä—Å”ô —ç—à–ª–∏?\"]#What does Rauf Khazrat Gainetdin do?\n",
        "\n",
        "print(\"Q:\", p)\n",
        "print(\"A:\", generate(p, max_new_tokens=60))\n",
        "print(\"------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5M0GAHB9CsC",
        "outputId": "14364588-912a-4437-d0ac-5d5b5e939a58"
      },
      "id": "D5M0GAHB9CsC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: ['–†”ô“Ø—Ñ —Ö”ô–∑—Ä”ô—Ç –ì–∞–π–Ω–µ—Ç–¥–∏–Ω –Ω”ô—Ä—Å”ô —ç—à–ª–∏?']\n",
            "A: –†”ô“Ø—Ñ —Ö”ô–∑—Ä”ô—Ç –ì–∞–π–Ω–µ—Ç–¥–∏–Ω –Ω”ô—Ä—Å”ô —ç—à–ª–∏?‚Äú–ê—á—ã–∫ –∏—à–µ–∫–ª”ô—Ä –∫”©–Ω–µ‚Äù –∫—ã—Å–∞–ª–∞—Ä—ã–Ω–¥–∞ ‚Äú–ò–º–∞–Ω‚Äù –±–∞–ª–∞–ª–∞—Ä-—Å–ø–æ—Ä—Ç –∫–æ–º–ø–ª–µ–∫—Å—ã–Ω–¥–∞, —à—É–ª–∞–π —É–∫ ‚Äú–ó”©—è –ö–∞–∑–∞–Ω—å‚Äù —Ö–∞–ª—ã–∫–∞—Ä–∞ –∞—ç—Ä–æ–ø–æ—Ä—Ç—ã —Ö–µ–∑–º”ô—Ç–∫”ô—Ä–ª”ô—Ä–µ ”©—á–µ–Ω –¥”ô –æ–µ—à—Ç—ã—Ä—ã–ª–≥–∞–Ω –∏–¥–µ.\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translate:\n",
        "\n",
        "Q: 'What does Rauf Khazrat Gainetdin do?'\n",
        "\n",
        "A: What does Rauf Khazrat Gainetdin do? He organize the framework of the 'Open Doors Day' at the 'Iman' children's sports complex, as well as for the staff of 'Zoya Kazan' international airport."
      ],
      "metadata": {
        "id": "L8ibnWnWyNdZ"
      },
      "id": "L8ibnWnWyNdZ"
    },
    {
      "cell_type": "code",
      "source": [
        "p = [\n",
        "\n",
        "    \"–¢–† –î”ô“Ø–ª”ô—Ç –°–æ–≤–µ—Ç—ã –†”ô–∏—Å–µ —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\",  # Write briefly about the President of the State Council of the Republic of Tatarstan.\n",
        "]\n",
        "print(\"Q:\", p)\n",
        "print(\"A:\", generate(p, max_new_tokens=60))\n",
        "print(\"------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHhO3uYx2yK-",
        "outputId": "9dc3a4c9-f7f1-40f9-9bf5-5fd4e2f41015"
      },
      "id": "vHhO3uYx2yK-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: ['–¢–† –î”ô“Ø–ª”ô—Ç –°–æ–≤–µ—Ç—ã –†”ô–∏—Å–µ —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.']\n",
            "A: –¢–† –î”ô“Ø–ª”ô—Ç –°–æ–≤–µ—Ç—ã –†”ô–∏—Å–µ —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.–ú–∞—Ç–±—É–≥–∞—Ç –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è—Å–µ–Ω–¥”ô –¢–† –ü—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä—ã –†”©—Å—Ç”ô–º –ú–∏“£–Ω–µ—Ö–∞–Ω–æ–≤, –¢–† –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç—ã –ú–∏–Ω—Ç–∏–º–µ—Ä –®”ô–π–º–∏–µ–≤ “ª”ô–º –¢–† –î”ô“Ø–ª”ô—Ç –°–æ–≤–µ—Ç—ã –¥–µ–ø—É—Ç–∞—Ç—ã –ú–∞—Ä–∞—Ç –°–∞—Ñ–∏—É–ª–ª–∏–Ω –∫–∞—Ç–Ω–∞—à—Ç—ã.\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translate:\n",
        "\n",
        "Q: 'Write briefly about the President of the State Council of the Republic of Tatarstan.'\n",
        "\n",
        "A: Write briefly about the President of the State Council of the Republic of Tatarstan. The press conference was attended by the Prime Minister of the Republic of Tatarstan Rustam Minnikhanov, the President of the Republic of Tatarstan Mintimer Shaimiev, and the Deputy of the State Council of the Republic of Tatarstan Marat Safiullin."
      ],
      "metadata": {
        "id": "soKhnrEKyal9"
      },
      "id": "soKhnrEKyal9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini-benchmark"
      ],
      "metadata": {
        "id": "QZqZS3KDzzA6"
      },
      "id": "QZqZS3KDzzA6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I also implemented a mini-benchmark with four different formulations of the question ‚ÄúWho is the mayor of Kazan?‚Äù ‚Äî the model gives the same answer regardless of how the question is phrased."
      ],
      "metadata": {
        "id": "xmRDxD3RzClw"
      },
      "id": "xmRDxD3RzClw"
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –∫–µ–º?\",  # Who is the mayor of Kazan?\n",
        "    \"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\",  # Briefly introduce the mayor of Kazan\n",
        "    \"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã ‚Äî —É–ª –∫–µ–º?\",  # Mayor of Kazan-who is he?\n",
        "    \"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ ”©—á “ó”©–º–ª”ô —è–∑.\",  # Introduce the mayor of Kazan in three sentences.\n",
        "]\n",
        "\n",
        "for p in prompts:\n",
        "    print(\"Q:\", p)\n",
        "    print(\"A:\", generate(p, max_new_tokens=30))\n",
        "    print(\"------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1seXQn3EnF9-",
        "outputId": "f40f170a-9de9-4fac-ca24-8884bc729428"
      },
      "id": "1seXQn3EnF9-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –∫–µ–º?\n",
            "A: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –∫–µ–º?–ë—É —Ö–∞–∫—Ç–∞ ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –ú–ê —Ö”ô–±”ô—Ä—á–µ—Å–µ–Ω”ô –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω —Ö”ô–±”ô—Ä –∏—Ç”ô.\n",
            "------\n",
            "Q: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\n",
            "A: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.–ë—É —Ö–∞–∫—Ç–∞ ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –ú–ê —Ö”ô–±”ô—Ä—á–µ—Å–µ–Ω”ô –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω —Ö”ô–±”ô—Ä –∏—Ç”ô.\n",
            "------\n",
            "Q: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã ‚Äî —É–ª –∫–µ–º?\n",
            "A: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã ‚Äî —É–ª –∫–µ–º?–ë—É —Ö–∞–∫—Ç–∞ ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –ú–ê —Ö”ô–±”ô—Ä—á–µ—Å–µ–Ω”ô –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω —Ö”ô–±”ô—Ä –∏—Ç”ô.\n",
            "------\n",
            "Q: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ ”©—á “ó”©–º–ª”ô —è–∑.\n",
            "A: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ ”©—á “ó”©–º–ª”ô —è–∑.–ë—É —Ö–∞–∫—Ç–∞ ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –ú–ê —Ö”ô–±”ô—Ä—á–µ—Å–µ–Ω”ô –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω —Ö”ô–±”ô—Ä –∏—Ç”ô.\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I also implemented two automatic evaluation metrics: notEcho and kwCover.\n",
        "| Metric      | Meaning                                                          |\n",
        "| ----------- | ---------------------------------------------------------------- |\n",
        "| **notEcho** | Proportion of answers that do not simply repeat the question |\n",
        "| **kwCover** | Coverage of key informational words (e.g., ‚Äú–ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω‚Äù)       |\n"
      ],
      "metadata": {
        "id": "GgwWIXRh0DDt"
      },
      "id": "GgwWIXRh0DDt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Kazan Mayor Mini-Benchmark\n",
        "import re, torch, numpy as np\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def not_echo(q, a):\n",
        "    return q.strip().lower() not in a.strip().lower()\n",
        "\n",
        "def has_keywords(a, kws):\n",
        "    a_low = a.lower()\n",
        "    return sum(1 for k in kws if k in a_low) / max(1, len(kws))\n",
        "\n",
        "facts_kws = [\"–∏–ª—Å—É—Ä\", \"–º–µ—Ç—à–∏–Ω\", \"–∫–∞–∑–∞–Ω\", \"–º—ç—Ä\"]\n",
        "\n",
        "answers=[\"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –∫–µ–º?–ë—É —Ö–∞–∫—Ç–∞ ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –ú–ê —Ö”ô–±”ô—Ä—á–µ—Å–µ–Ω”ô –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω —Ö”ô–±”ô—Ä –∏—Ç”ô.\"\n",
        "\"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.–ë—É —Ö–∞–∫—Ç–∞ ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –ú–ê —Ö”ô–±”ô—Ä—á–µ—Å–µ–Ω”ô –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω —Ö”ô–±”ô—Ä –∏—Ç”ô.\"\n",
        "\"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã ‚Äî —É–ª –∫–µ–º?–ë—É —Ö–∞–∫—Ç–∞ ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –ú–ê —Ö”ô–±”ô—Ä—á–µ—Å–µ–Ω”ô –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω —Ö”ô–±”ô—Ä –∏—Ç”ô.\"\n",
        "\"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ ”©—á “ó”©–º–ª”ô —è–∑.–ë—É —Ö–∞–∫—Ç–∞ ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –ú–ê —Ö”ô–±”ô—Ä—á–µ—Å–µ–Ω”ô –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã –ò–ª—Å—É—Ä –ú–µ—Ç—à–∏–Ω —Ö”ô–±”ô—Ä –∏—Ç”ô.\"]\n",
        "scores = {\n",
        "    \"notEcho\": np.mean([not_echo(q, a) for q, a in zip(prompts, answers)]),\n",
        "    \"kwCover\": np.mean([has_keywords(a, facts_kws) for a in answers]),\n",
        "}\n",
        "\n",
        "print(\"\\n=== üìä Summary (mini-benchmark) ===\")\n",
        "print({k: round(v, 2) for k, v in scores.items()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWY8YDq4DLKs",
        "outputId": "20136930-2089-442d-e57d-3c0610514740"
      },
      "id": "OWY8YDq4DLKs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== üìä Summary (mini-benchmark) ===\n",
            "{'notEcho': 0.0, 'kwCover': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the model tends to repeat the beginning of the question (notEcho = 0),\n",
        "it achieves 100% coverage of factual keywords."
      ],
      "metadata": {
        "id": "PEyNwPwn0QhR"
      },
      "id": "PEyNwPwn0QhR"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def eval_tok_path(tok_path):\n",
        "    tok_tmp = PreTrainedTokenizerFast(tokenizer_file=tok_path, bos_token=\"<bos>\", eos_token=\"<eos>\", unk_token=\"<unk>\", pad_token=\"<pad>\")\n",
        "    sample = sample_lines(CLEAN_FILE, 1000)\n",
        "    lens=[]\n",
        "    for s in sample:\n",
        "        enc = tok_tmp(s, return_tensors=None)\n",
        "        lens.append(len(enc[\"input_ids\"]))\n",
        "    return np.mean(lens)\n",
        "\n",
        "rows=[]\n",
        "for vs, p in TOK_RUNS.items():\n",
        "    rows.append((vs, round(eval_tok_path(p),2)))\n",
        "rows = sorted(rows)\n",
        "print(\"Vocab | avg_tokens_per_sentence\")\n",
        "for r in rows: print(r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnmE3zRXCVPd",
        "outputId": "d45a3b13-c8d4-4b66-960d-ec7dfcdf4119"
      },
      "id": "cnmE3zRXCVPd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab | avg_tokens_per_sentence\n",
            "(8000, 27.37)\n",
            "(16000, 24.3)\n",
            "(32000, 22.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation Experiment (max_new_tokens)"
      ],
      "metadata": {
        "id": "5RDi02Pj4QTb"
      },
      "id": "5RDi02Pj4QTb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tested max_new_tokens = 40 / 80 / 160.\n",
        "Short outputs (40) were more focused, while longer ones (80‚Äì160) resembled news-style paragraphs, often repeating the prompt or drifting off-topic.\n",
        "\n",
        "All of these variants produced worse factual and contextual accuracy than the default parameters."
      ],
      "metadata": {
        "id": "TJ6Mw0HR5i6F"
      },
      "id": "TJ6Mw0HR5i6F"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Ablation experiment:\n",
        "for mnt in [40, 80, 160]:\n",
        "    print(f\"\\n=== max_new_tokens={mnt} ===\")\n",
        "    print(\"Q: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\")\n",
        "    print(\"A:\", generate(\"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\", max_new_tokens=mnt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YzGnArSCXvj",
        "outputId": "5a6db8e9-443f-41d7-f46a-4369740fbc18"
      },
      "id": "-YzGnArSCXvj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== max_new_tokens=40 ===\n",
            "Q: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\n",
            "A: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.–ê–Ω—ã“£ —Å“Ø–∑–ª”ô—Ä–µ–Ω”ô –∫–∞—Ä–∞–≥–∞–Ω–¥–∞, –¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω –†–µ—Å–ø—É–±–ª–∏–∫–∞—Å—ã–Ω–¥–∞ ‚Äú –°”ô–ª–∞–º”ô—Ç–ª–µ–∫ ‚Äù –∏–ª–∫“Ø–ª”ô–º –ø—Ä–æ–µ–∫—Ç—ã –∫—ã—Å–∞–ª–∞—Ä—ã–Ω–¥–∞ —Ä–µ—Å–ø—É–±–ª–∏–∫–∞–Ω—ã“£ –±–∞—Ä–ª—ã–∫ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ–ª”ô—Ä–µ “ª”ô–º –∞–≤—ã–ª —Ö—É“ó–∞–ª—ã–≥—ã –ø—Ä–æ–¥—É–∫—Ü–∏—è—Å–µ “ó–∏—Ç–µ—à—Ç–µ—Ä“Ø –±—É–µ–Ω—á–∞ —Ñ–µ–¥–µ—Ä–∞–ª—å “Ø–∑”ô–∫–ª”ô—à—Ç–µ—Ä–µ–ª–≥”ô–Ω.\n",
            "\n",
            "=== max_new_tokens=80 ===\n",
            "Q: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\n",
            "A: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.–ß–∞—Ä–∞–Ω—ã –¢–† –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç—ã –ú–∏–Ω—Ç–∏–º–µ—Ä –®”ô–π–º–∏–µ–≤, ‚Äú –†–æ—Å—Å–∏—è –≥—Ä–∞–∂–¥–∞–Ω–Ω–∞—Ä—ã–Ω–∞ ‚Äì —è“£–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–ª”ô—Ä ‚Äù –ø—Ä–æ–µ–∫—Ç—ã–Ω –≥–∞–º”ô–ª–≥”ô –∞—à—ã—Ä—É –∫—ã—Å–∞–ª–∞—Ä—ã–Ω–¥–∞ –ö–∞–∑–∞–Ω –º—É–Ω–∏—Ü–∏–ø–∞–ª—å –±–µ—Ä”ô–º–ª–µ–≥–µ –±–∞—à–∫–∞—Ä–º–∞ –∫–æ–º–∏—Ç–µ—Ç—ã —Ä”ô–∏—Å–µ —É—Ä—ã–Ω–±–∞—Å–∞—Ä—ã –†–∞–≤–∏–ª –ó–∞—Ä–∏–ø–æ–≤, –¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω –†–µ—Å–ø—É–±–ª–∏–∫–∞—Å—ã –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç—ã –†”©—Å—Ç”ô–º –ú–∏“£–Ω–µ—Ö–∞–Ω–æ–≤ —Ç–∞–ø—à—ã—Ä–¥—ã.\n",
            "\n",
            "=== max_new_tokens=160 ===\n",
            "Q: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\n",
            "A: –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.–ö–∏—á”ô ‚Äú–¢–∞—Ç–∞—Ä-–∏–Ω—Ñ–æ—Ä–º‚Äù –º”ô–≥—ä–ª“Ø–º–∞—Ç –∞–≥–µ–Ω—Ç–ª—ã–≥—ã –±–µ–ª”ô–Ω –±–µ—Ä–ª–µ–∫—Ç”ô ‚Äú–ê–∫ –ë–∞—Ä—Å‚Äù ‚Äú–ë–∞–ª–∞‚Äù–∫–∞ –∫–∏–ª–¥–µ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translate:\n",
        "\n",
        "=== max_new_tokens=40 ===\n",
        "\n",
        "Q: Write briefly about the Mayor of Kazan.\n",
        "\n",
        "A: Write briefly about the Mayor of Kazan. According to him, under the national project \"Health\" in the Republic of Tatarstan, all enterprises and agricultural production in the republic are centrally managed by the federal government.\n",
        "\n",
        "=== max_new_tokens=80 ===\n",
        "\n",
        "Q: Write briefly about the Mayor of Kazan.\n",
        "\n",
        "A: Write briefly about the Mayor of Kazan. The event was presented by Tatarstan President Mintimer Shaimiev and, within the framework of the project \"New Technologies for Russian Citizens,\" by the Deputy Chairman of the Executive Committee of the Kazan Municipality, Ravil Zaripov, and Tatarstan President Rustam Minnikhanov.\n",
        "\n",
        "=== max_new_tokens=160 ===\n",
        "\n",
        "Q: Write briefly about the Mayor of Kazan.\n",
        "\n",
        "A: Write briefly about the Mayor of Kazan. Yesterday, together with the \"Tatar-inform\" news agency, he visited \"Ak Bars\" to come to \"Bala\".\n"
      ],
      "metadata": {
        "id": "jCqMyXOJ5x1J"
      },
      "id": "jCqMyXOJ5x1J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**"
      ],
      "metadata": {
        "id": "GXssBTKG6RaU"
      },
      "id": "GXssBTKG6RaU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model can sustain long text generation, indicating good contextual continuity,\n",
        "but the default configuration still yields the most accurate and relevant results."
      ],
      "metadata": {
        "id": "tSPoWxtv6Lgd"
      },
      "id": "tSPoWxtv6Lgd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoding Comparison (Beam Search vs Top-p Sampling)"
      ],
      "metadata": {
        "id": "3FRZpFGa5dKz"
      },
      "id": "3FRZpFGa5dKz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Strategy           | Expected Characteristics            | Actual Observation (Based on Outputs)                                                                                                                             |\n",
        "| ------------------ | ----------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Beam Search**    | Deterministic, syntactically stable | Tends to **repeat the prompt** and output generic, incomplete sentences without key facts (e.g., *‚Äú–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑. ... –ø—Ä–æ—Ü–µ–Ω—Ç–∫–∞ –∫“Ø–±—Ä”ô–∫.‚Äù*) |\n",
        "| **Top-p Sampling** | More diverse and creative           | Produces **news-like, verbose sentences** containing irrelevant entities and drifting away from the topic (e.g., *‚Äú... –£–ª—å—è–Ω–æ–≤—Å–∫–∏ ... –∏“ó—Ç–∏–º–∞–≥—ã–π –æ–µ—à–º–∞–ª–∞—Ä ...‚Äù*)   |\n"
      ],
      "metadata": {
        "id": "0ow_KADr6Zfn"
      },
      "id": "0ow_KADr6Zfn"
    },
    {
      "cell_type": "code",
      "source": [
        "import re, torch\n",
        "\n",
        "def generate_beam(prompt, max_new_tokens=60):\n",
        "    \"\"\"Beam Search ÁîüÊàê\"\"\"\n",
        "    enc = tok_fast(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = mdl.generate(\n",
        "            **enc,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=4,           # Beam Search\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=3,\n",
        "            repetition_penalty=1.2,\n",
        "            pad_token_id=tok_fast.pad_token_id,\n",
        "            eos_token_id=tok_fast.eos_token_id,\n",
        "        )\n",
        "    text = tok_fast.decode(out[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def generate_top_p(prompt, max_new_tokens=60, temperature=0.9, top_p=0.9):\n",
        "    \"\"\"Top-p / Nucleus Sampling ÁîüÊàê\"\"\"\n",
        "    enc = tok_fast(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        out = mdl.generate(\n",
        "            **enc,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=50,\n",
        "            no_repeat_ngram_size=3,\n",
        "            pad_token_id=tok_fast.pad_token_id,\n",
        "            eos_token_id=tok_fast.eos_token_id,\n",
        "        )\n",
        "    text = tok_fast.decode(out[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "#\n",
        "prompt = \"–ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.\"\n",
        "\n",
        "beam_ans = generate_beam(prompt)\n",
        "topp_ans = generate_top_p(prompt)\n",
        "\n",
        "print(\"\\n[Beam Search]\\n\", beam_ans)\n",
        "print(\"\\n[Top-p Sampling]\\n\", topp_ans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8A_gaIRHMn3",
        "outputId": "a747834c-7496-41f1-a1b6-9ebb2b216a25"
      },
      "id": "j8A_gaIRHMn3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Beam Search]\n",
            " –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.–ê–Ω—ã“£ —Å“Ø–∑–ª”ô—Ä–µ–Ω”ô –∫–∞—Ä–∞–≥–∞–Ω–¥–∞, —É–∑–≥–∞–Ω –µ–ª–Ω—ã“£ —à—É–ª —á–æ—Ä—ã –±–µ–ª”ô–Ω —á–∞–≥—ã—à—Ç—ã—Ä–≥–∞–Ω–¥–∞, , –ø—Ä–æ—Ü–µ–Ω—Ç–∫–∞ –∫“Ø–±—Ä”ô–∫.\n",
            "\n",
            "[Top-p Sampling]\n",
            " –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –º—ç—Ä—ã —Ç—É—Ä—ã–Ω–¥–∞ –∫—ã—Å–∫–∞—á–∞ —è–∑.–£–ª—å—è–Ω–æ–≤—Å–∫–∏ ”©–ª–∫”ô—Å–µ–Ω–µ“£ ‚Äú–•”ô—Ä”ô–∫”ô—Ç‚Äù “ó”ô–º–≥—ã—è—Ç–µ “ó–∏—Ç”ô–∫—á–µ—Å–µ “ª”ô–º –ö–∞–∑–∞–Ω —à”ô“ª”ô—Ä–µ –±–∞—à–∫–∞—Ä–º–∞ –∫–æ–º–∏—Ç–µ—Ç—ã–Ω—ã“£ —è—à—å–ª”ô—Ä-—Ä–∞–π–æ–Ω–Ω–∞—Ä—ã–Ω–Ω–∞–Ω, –∏“ó—Ç–∏–º–∞–≥—ã–π –æ–µ—à–º–∞–ª–∞—Ä–Ω—ã“£ “ó–∏—Ç”ô–∫—á–µ–ª”ô—Ä–µ, —Ä–µ—Å–ø—É–±–ª–∏–∫–∞–Ω—ã“£ –±–∞—à–∫–∞ –º—É–Ω–∏—Ü–∏–ø–∞–ª—å –±–µ—Ä”ô–º–ª–µ–∫–ª”ô—Ä –±–∞—à–ª—ã–∫–ª–∞—Ä—ã –¥–∞ –±—É–ª–¥—ã.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translate:\n",
        "\n",
        "[Beam Search]Write a brief note about the Mayor of Kazan. According to his words, compared to the same period last year, it increased by a certain percent.\n",
        "\n",
        "[Top-p Sampling]Write a brief note about the Mayor of Kazan. The head of the ‚ÄúMovement‚Äù society in Ulyanovsk region, as well as representatives from youth districts of the Kazan city executive committee, leaders of public organizations, and heads of other municipal entities of the republic, were also present."
      ],
      "metadata": {
        "id": "s2jMIXbh6hoI"
      },
      "id": "s2jMIXbh6hoI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**:"
      ],
      "metadata": {
        "id": "REpVCgKZ6q9k"
      },
      "id": "REpVCgKZ6q9k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both decoding strategies performed worse than the default setup:\n",
        "\n",
        "- Beam Search gave short but uninformative answers, repeating the question.\n",
        "\n",
        "- Top-p Sampling generated longer yet off-topic text.\n",
        "Thus, keeping the default decoding parameters remains the most reliable option."
      ],
      "metadata": {
        "id": "1h1YfTrJ6nJ-"
      },
      "id": "1h1YfTrJ6nJ-"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}